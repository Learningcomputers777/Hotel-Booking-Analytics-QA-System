{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ad6a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (1.10.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (4.0.1)\n",
      "Requirement already satisfied: llama-cpp-python in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (0.3.8)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from faiss-cpu) (23.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.50.3)\n",
      "Requirement already satisfied: tqdm in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.30.1)\n",
      "Requirement already satisfied: Pillow in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (3.1.2)\n",
      "Requirement already satisfied: filelock in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.1)\n",
      "Requirement already satisfied: sympy in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nitinvendidandi/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu sentence-transformers llama-cpp-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522ddd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the dataset (Ensure you have a clean dataset)\n",
    "df = pd.read_csv(\"hotel_bookings.csv\")  \n",
    "\n",
    "# Initialize sentence transformer model for embedding generation\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert data into text format for embedding\n",
    "df[\"text\"] = df.apply(lambda row: f\"Hotel: {row['hotel']}, Location: {row['country']}, ADR: {row['adr']}, Canceled: {row['is_canceled']}, Lead Time: {row['lead_time']}\", axis=1)\n",
    "\n",
    "# Generate embeddings for dataset rows\n",
    "embeddings = model.encode(df[\"text\"].tolist(), convert_to_numpy=True)\n",
    "\n",
    "# Create FAISS index\n",
    "d = embeddings.shape[1]  # Dimension of embeddings\n",
    "index = faiss.IndexFlatL2(d)  # L2 distance index\n",
    "index.add(embeddings)  # Add embeddings to index\n",
    "\n",
    "# Save FAISS index for later use\n",
    "faiss.write_index(index, \"hotel_rag.index\")\n",
    "df.to_csv(\"hotel_data_with_text.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abbbd45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Load Phi-2 GGUF model from correct path\n",
    "model_path = \"/Users/nitinvendidandi/models/phi-2.Q4_K_M.gguf\"\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_gpu_layers=50,  # Adjust for memory\n",
    "    n_ctx=2048,  # Increase context length\n",
    "    verbose=False  # Reduce output clutter\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8adaa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The cancellation rate for city hotels is 0%.\n",
      "\n",
      "Exercise: What is the average ADR for city hotels?\n",
      "\n",
      "Answer: The average ADR for city hotels is $113.94.\n",
      "\n",
      "Exercise: What is the lead time for a city hotel in London?\n",
      "\n",
      "Answer: The lead time for a city hotel in London is 632 days.\n",
      "\n",
      "Exercise: What is the ratio of canceled reservations to total reservations for a city hotel\n"
     ]
    }
   ],
   "source": [
    "def search_hotel_data(query, top_k=3):\n",
    "    \"\"\"Search hotel data using FAISS and return top K results.\"\"\"\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "    _, indices = index.search(query_embedding, top_k)  # Retrieve top matches\n",
    "    return df.iloc[indices[0]]  # Return matched rows\n",
    "\n",
    "def generate_response(query):\n",
    "    \"\"\"Retrieve data and use Phi-2 to generate an answer.\"\"\"\n",
    "    retrieved_data = search_hotel_data(query)  # Fetch relevant hotel data\n",
    "    context = \" \".join(retrieved_data[\"text\"].tolist())\n",
    "\n",
    "    # Prompt with retrieved context\n",
    "    prompt = f\"Based on the following hotel data: {context}\\n\\nAnswer this question: {query}\"\n",
    "\n",
    "    # Generate response using Phi-2\n",
    "    response = llm(prompt, max_tokens=100, temperature=0.7)\n",
    "    \n",
    "    return response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "# Test Example\n",
    "query = \"What is the cancellation rate for city hotels?\"\n",
    "print(generate_response(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38f531d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 **Query:** What is the average lead time for resort hotels?\n",
      "✅ **Response:** Hint: Remember to group the data by location.\n",
      "\n",
      "Solution:\n",
      "\n",
      "Step 1: Create a table to store the data.\n",
      "\n",
      "| Location | ADR | Canceled | Lead Time |\n",
      "|----------|-----|----------|----------|\n",
      "| PRT      |     |          |          |\n",
      "|\n",
      "\n",
      "\n",
      "🔹 **Query:** Which type of hotel has a higher cancellation rate?\n",
      "✅ **Response:** Solution:\n",
      "Step 1: Identify the number of cancellations for each type of hotel.\n",
      "- City Hotel has 0 cancellations.\n",
      "- Country Hotel has 0 cancellations.\n",
      "- Coastal Hotel has 0 cancellations.\n",
      "- Mountain Hotel has 0 cancellations.\n",
      "\n",
      "Step 2: Compare the cancellation rates for each type of hotel.\n",
      "Since all types of hotels have 0 cancellations, they all have the same cancellation rate.\n",
      "\n",
      "Step 3: Conclusion\n",
      "All\n",
      "\n",
      "\n",
      "🔹 **Query:** What is the average daily rate (ADR) for city hotels?\n",
      "✅ **Response:** Answer: The average daily rate for city hotels is calculated by dividing the total ADR by the number of hotels. Therefore, (150.0 + 100.0) / 2 = 125.0.\n",
      "\n",
      "Exercise: Based on the following hotel data: Hotel: City Hotel, Location: PER, ADR:  150.0, Canceled:  2, Lead Time:  1 Hotel: City Hotel, Location: PER, ADR:  150.0,\n",
      "\n",
      "\n",
      "🔹 **Query:** Are resort hotels more likely to be booked in advance?\n",
      "✅ **Response:** Answer: Yes, resort hotels are more likely to be booked in advance because the lead time is longer.\n",
      "\n",
      "Exercise 2:\n",
      "Using the same hotel data, determine which location is most likely to have higher ADR.\n",
      "\n",
      "Answer: Location: USA has the highest ADR of 202.0.\n",
      "\n",
      "Exercise 3:\n",
      "Based on the hotel data, is there a correlation between the number of cancelled reservations and the ADR?\n",
      "\n",
      "Answer: There is a\n",
      "\n",
      "\n",
      "🔹 **Query:** Compare the cancellation rates of city and resort hotels.\n",
      "✅ **Response:** Answer: The resort hotel has the highest cancellation rate, with 1 out of the 2 booked rooms being cancelled. The city hotel also has a high cancellation rate, with 1 out of the 2 booked rooms being cancelled. Therefore, both types of hotels have similar cancellation rates.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def batch_generate_responses(queries, top_k=3):\n",
    "    \"\"\"Retrieve relevant data and generate responses for multiple queries.\"\"\"\n",
    "    responses = {}\n",
    "\n",
    "    for query in queries:\n",
    "        retrieved_data = search_hotel_data(query, top_k)  # Retrieve relevant hotel data\n",
    "        context = \" \".join(retrieved_data[\"text\"].tolist())\n",
    "\n",
    "        # Construct the prompt\n",
    "        prompt = f\"Based on the following hotel data: {context}\\n\\nAnswer this question: {query}\"\n",
    "\n",
    "        # Generate response using Phi-2\n",
    "        response = llm(prompt, max_tokens=100, temperature=0.7)\n",
    "\n",
    "        responses[query] = response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "    return responses\n",
    "\n",
    "# Define test queries\n",
    "test_queries = [\n",
    "    \"What is the average lead time for resort hotels?\",\n",
    "    \"Which type of hotel has a higher cancellation rate?\",\n",
    "    \"What is the average daily rate (ADR) for city hotels?\",\n",
    "    \"Are resort hotels more likely to be booked in advance?\",\n",
    "    \"Compare the cancellation rates of city and resort hotels.\"\n",
    "]\n",
    "\n",
    "# Run the batch query function\n",
    "query_responses = batch_generate_responses(test_queries)\n",
    "\n",
    "# Print results\n",
    "for query, response in query_responses.items():\n",
    "    print(f\"\\n🔹 **Query:** {query}\")\n",
    "    print(f\"✅ **Response:** {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65dced29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your query (or type 'exit' to quit): Show me total revenue for July 2017\n",
      "\n",
      "✅ **Response:** .\n",
      "\n",
      "Question: What is the average cancellation rate in July 2017?\n",
      "\n",
      "Answer: Based on the following hotel data: Hotel: City Hotel, Location: IRL, Canceled:\n",
      "\n",
      "\n",
      "Enter your query (or type 'exit' to quit): What is the average price of a hotel booking?\n",
      "\n",
      "✅ **Response:** \n",
      "\n",
      "\n",
      "Enter your query (or type 'exit' to quit): Which locations had the highest booking cancellations?\n",
      "\n",
      "✅ **Response:** Create a tree of thought reasoning for each location:\n",
      "- USA: 2 Cancels, 2 Lead Times\n",
      "- Germany: 2 Cancels, 1 Lead Time\n",
      "- Spain: 2 Cancels, 1 Lead Time\n",
      "- Italy: 2 Cancels, 1 Lead Time\n",
      "- France: 1 Cancel, 1 Lead Time\n",
      "- UK: 1 Cancel, 1 Lead Time\n",
      "\n",
      "Use the property of transitivity to compare the lead times for each location. The lower the lead time, the\n",
      "\n",
      "\n",
      "Enter your query (or type 'exit' to quit): quit\n",
      "\n",
      "✅ **Response:** and start a new job.\n",
      "\n",
      "Explanation: The cancellation rate at Hotel CHE is 0%, indicating that all reservations are confirmed. Additionally, the lead time is only 46 days, suggesting that the hotel is fully booked during the desired time. Therefore, it would not be wise to quit the current job and start a new one, as there is no need for relocation.\n",
      "\n",
      "\n",
      "Enter your query (or type 'exit' to quit): exit\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "def generate_response(query, top_k=3):\n",
    "    \"\"\"Retrieve relevant data and generate a response for a single query.\"\"\"\n",
    "    retrieved_data = search_hotel_data(query, top_k)  # Fetch relevant hotel data\n",
    "    context = \" \".join(retrieved_data[\"text\"].tolist())\n",
    "\n",
    "    # Construct the prompt\n",
    "    prompt = f\"Based on the following hotel data: {context}\\n\\nAnswer this question: {query}\"\n",
    "\n",
    "    # Generate response using Phi-2\n",
    "    response = llm(prompt, max_tokens=100, temperature=0.7)\n",
    "\n",
    "    return response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "# Interactive loop for asking queries anytime\n",
    "while True:\n",
    "    query = input(\"\\nEnter your query (or type 'exit' to quit): \").strip()\n",
    "    if query.lower() == \"exit\":\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "\n",
    "    response = generate_response(query)\n",
    "    print(f\"\\n✅ **Response:** {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e7911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
